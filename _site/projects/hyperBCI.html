<!doctype html>
<html>
  <head>
    <meta charset="utf-8">
    <title>HyperLoRA: Unsupervised Adaptation via Low-Rank Hypernetwork Weight Generation</title>
    <link rel="stylesheet" href="/assets/css/styles.css">
  </head>
  <body>
    <div class="container">
      <div class="nav-tabs">
        <nav>
  <div style="text-align: center;">
    
      <a href="/" >Home</a>
    
      <a href="/projects.html" >Projects</a>
    
      <a href="/publications.html" >Publications</a>
    
      <a href="/awards.html" >Awards</a>
    
  </div>
</nav>
      </div>
      <div class="content-section">
  <h1>HyperLoRA: Unsupervised Adaptation via Low-Rank Hypernetwork Weight Generation</h1>
  
  
    <p class="text-muted mb-3">Developed hypernetwork-based framework for generating LoRA matrices from unlabeled target-domain data, enabling rapid online adaptation of deep learning models. Applied here to self-calibrating BCIs.</p>
  

  <div class="button-container">
    
      
      <a href="https://people.cs.uchicago.edu/~hankhoffmann/" class="button button-small">Henry Hoffmann Lab</a>
    

    

    
      <a href="/assets/slides/20240816_ai_for_bio_presentation.pdf" class="button button-small">ðŸ“Š View Slides</a>
    

    
      <a href="https://github.com/jhanliufu-personal/HypernetBCI" class="button button-small">ðŸ’» View Code</a>
    

    
  </div>
</div>

<div class="content-section">
  <h2 id="project-description">Project description</h2>
<div style="font-size: 20px;">
    <!-- <p>
    Deep learning (DL) based brain computer interface (BCI) models are powerful algorithms for mapping brain activity to human interpretable concepts in real time. Such models have been used to develop neural prostheses to serve patients suffering from different disabilities. Due to the neural differences between individuals, BCI models need to be calibrated to perform accurately on a new user. Due to the non-stationarity of neural activity, BCI models also need to be repeatedly adjusted to stay accurate throughout the usage of one user. Both are examples of the broader problem of <strong>unsupervised domain adaptation (UDA)</strong> in machine learning. Existing UDA methods often require labeled data from new users for supervised training or large amounts of unlabeled data from both existing and new users for iterative, computationally intensive alignment processes. These data requirements pose significant challenges for real-time BCI applications on edge devices like brain implantable chips.
    </p>
    <p>
    To address this challenge, we design <strong>HyperBCI for unsupervised, data-efficient and computation-efficient calibration</strong>. HyperBCI is designed to extract information from unlabeled brain data and generate near-optimal network weights according to the extracted information. The proposed calibration method only involves forward passing the recorded data and is therefore free of any iterative optimization process. 
    We deploy HyperBCI on an <strong>FPGA</strong>-based neural implant and achieve closed-loop and low-power operation using <strong>TinyML</strong> techniques. The implant will be implanted into a freely behaving rodent to demonstrate its potential for real-life applications. HyperBCI will enable self-calibrating BCI systems that self-calibrate and thus maintain reliable performance through the long run.
    </p> -->
    <p>
    Modern deep learning models often face significant performance drops when deployed in new domains unseen during training. To address this, we propose a general-purpose <strong>unsupervised adaptation</strong> framework that combines Low-Rank Adaptation (<strong>LoRA</strong>) with <strong>hypernetwork</strong>. Our architecture takes the latent embedding of unlabeled data from a new domain, feeds it into a hypernetwork, and generates the LoRA adapter for a pre-trained base model. Our architecture achieves rapid adaptation in a single forward pass. It does not require iterative optimization or large volumes of paired source-target data. This makes it highly suitable for time-critical or resource-constrained applications.
    </p>
    <p>
    Application to Brain-Computer Interfaces (<strong>BCI</strong>): In online BCI settings, neural signals differ significantly between patients, and even within the same patient over time. Using our LoRA-hypernetwork framework, we perform <strong>unsupervised, on-device adaptation</strong> for new patients by processing a short segment of their unlabeled brain data. We generate LoRA adapters the model's last few layers in real time, enabling the BCI to stay accurate without disruptive calibration sessions. 
    <!-- We implement this approach on an <strong>FPGA-based neural implant</strong> using <strong>TinyML</strong> techniques, achieving closed-loop, low-power operation in freely behaving rodents. -->
    </p>
    <p>
    This project led to my Bachelor's <a href="/assets/written_reports/mliufu_cs_thesis_20250425.pdf" style="color: blue; text-decoration: underline;">thesis</a> in CS. I'm currently working towards publication. 
    </p>
</div>

<div align="center">
    <img src="/assets/images/hyperBCI_graphical_abstract.png" alt="Example Image" width="800" />
    <p style="text-align: left; font-size: 16px;">
        <strong>Figure 1.</strong> Schematic of HyperBCI, a hypernetwork-based self-calibrating BCI system. The primary network and the hypernetwork are jointly pre-trained on a pool of existing users. During inference time, unsupervised adaptation is achieved through the hypernetwork which is consisted of the encoder and the weight generator. The encoder processes unlableled data from new user and generates an embedding, which instructs the weight generator to produce near-optimal model weights for the new subject.
    </p>
<div>


</div></div>

</div>
    </div>
  </body>
</html>

